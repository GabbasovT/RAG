{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Скрипт для обучения RAG системы\n",
    "Поддерживает три режима:\n",
    "1. Обучение только ретривера (DPR)\n",
    "2. Обучение только генератора (BART)\n",
    "3. End-to-end обучение всей RAG системы"
   ],
   "id": "a31f440ac640c0e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:36:05.465142Z",
     "start_time": "2025-11-21T15:36:04.634966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "from lib.training_data import (\n",
    "    RetrieverDataset,\n",
    "    GeneratorDataset,\n",
    "    RAGDataset,\n",
    "    create_sample_training_data\n",
    ")\n",
    "from lib.retriever_training import DPRRetrieverTrainer\n",
    "from lib.generator_training import BARTGeneratorTrainer\n",
    "from lib.rag_training import RAGEndToEndTrainer\n"
   ],
   "id": "f1e5d3026f628c99",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01margparse\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_fn_retriever(batch):\n",
    "    \"\"\"Collate function для RetrieverDataset\"\"\"\n",
    "    queries = [item['query'] for item in batch]\n",
    "    positive_passages = [item['positive_passage'] for item in batch]\n",
    "    negative_passages = [item['negative_passages'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'query': queries,\n",
    "        'positive_passage': positive_passages,\n",
    "        'negative_passages': negative_passages\n",
    "    }"
   ],
   "id": "ac3e5137226f5110"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_fn_generator(batch):\n",
    "    \"\"\"Collate function для GeneratorDataset\"\"\"\n",
    "    questions = [item['question'] for item in batch]\n",
    "    contexts = [item['context'] for item in batch]\n",
    "    answers = [item['answer'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'question': questions,\n",
    "        'context': contexts,\n",
    "        'answer': answers\n",
    "    }"
   ],
   "id": "4748f23d98fcef86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_fn_rag(batch):\n",
    "    \"\"\"Collate function для RAGDataset\"\"\"\n",
    "    questions = [item['question'] for item in batch]\n",
    "    answers = [item['answer'] for item in batch]\n",
    "    positive_contexts = [item['positive_context'] for item in batch]\n",
    "    negative_contexts = [item['negative_contexts'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'question': questions,\n",
    "        'answer': answers,\n",
    "        'positive_context': positive_contexts,\n",
    "        'negative_contexts': negative_contexts\n",
    "    }"
   ],
   "id": "5a6ca93613877b50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_retriever(args):\n",
    "    \"\"\"\n",
    "    Обучение DPR ретривера\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ОБУЧЕНИЕ DPR РЕТРИВЕРА\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    qa_pairs = create_sample_training_data()\n",
    "    \n",
    "    qa_pairs = qa_pairs * 20\n",
    "    \n",
    "    all_passages = list(set([qa['context'] for qa in qa_pairs]))\n",
    "    \n",
    "    dataset = RetrieverDataset.from_qa_pairs(\n",
    "        qa_pairs=qa_pairs,\n",
    "        all_passages=all_passages,\n",
    "        num_hard_negatives=args.num_hard_negatives\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_retriever\n",
    "    )\n",
    "    \n",
    "    trainer = DPRRetrieverTrainer(\n",
    "        learning_rate=args.learning_rate,\n",
    "        max_length=args.max_length\n",
    "    )\n",
    "    \n",
    "    losses = trainer.train(\n",
    "        train_dataloader=dataloader,\n",
    "        num_epochs=args.num_epochs,\n",
    "        use_in_batch_negatives=args.use_in_batch_negatives,\n",
    "        warmup_steps=args.warmup_steps,\n",
    "        logging_steps=args.logging_steps\n",
    "    )\n",
    "    \n",
    "    if args.output_dir:\n",
    "        trainer.save_model(args.output_dir)\n",
    "    \n",
    "    return losses\n"
   ],
   "id": "435ac416ec8053c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_generator(args):\n",
    "    \"\"\"\n",
    "    Обучение BART генератора\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ОБУЧЕНИЕ BART ГЕНЕРАТОРА\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    qa_pairs = create_sample_training_data()\n",
    "    qa_pairs = qa_pairs * 20\n",
    "    \n",
    "    dataset = GeneratorDataset.from_qa_pairs(\n",
    "        qa_pairs=qa_pairs,\n",
    "        max_input_length=args.max_input_length,\n",
    "        max_output_length=args.max_output_length\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_generator\n",
    "    )\n",
    "    \n",
    "    trainer = BARTGeneratorTrainer(\n",
    "        learning_rate=args.learning_rate,\n",
    "        max_input_length=args.max_input_length,\n",
    "        max_output_length=args.max_output_length\n",
    "    )\n",
    "    \n",
    "    losses = trainer.train(\n",
    "        train_dataloader=dataloader,\n",
    "        num_epochs=args.num_epochs,\n",
    "        warmup_steps=args.warmup_steps,\n",
    "        logging_steps=args.logging_steps\n",
    "    )\n",
    "    \n",
    "    if args.output_dir:\n",
    "        trainer.save_model(args.output_dir)\n",
    "    \n",
    "    return losses\n"
   ],
   "id": "67d0fb35bfa89aeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_rag_end_to_end(args):\n",
    "    \"\"\"\n",
    "    End-to-end обучение RAG системы\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"END-TO-END ОБУЧЕНИЕ RAG СИСТЕМЫ\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    qa_pairs = create_sample_training_data()\n",
    "    qa_pairs = qa_pairs * 20\n",
    "    \n",
    "    all_passages = list(set([qa['context'] for qa in qa_pairs]))\n",
    "    \n",
    "    print(f\"Количество примеров: {len(qa_pairs)}\")\n",
    "    print(f\"Количество уникальных контекстов: {len(all_passages)}\")\n",
    "    \n",
    "    dataset = RAGDataset.from_qa_pairs(\n",
    "        qa_pairs=qa_pairs,\n",
    "        all_passages=all_passages,\n",
    "        num_hard_negatives=args.num_hard_negatives,\n",
    "        max_input_length=args.max_input_length,\n",
    "        max_output_length=args.max_output_length\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_rag\n",
    "    )\n",
    "    \n",
    "    trainer = RAGEndToEndTrainer(\n",
    "        learning_rate=args.learning_rate,\n",
    "        retriever_weight=args.retriever_weight,\n",
    "        generator_weight=args.generator_weight,\n",
    "        max_input_length=args.max_input_length,\n",
    "        max_output_length=args.max_output_length,\n",
    "        top_k_retrieval=args.top_k_retrieval\n",
    "    )\n",
    "    \n",
    "    losses = trainer.train(\n",
    "        train_dataloader=dataloader,\n",
    "        all_contexts=all_passages,\n",
    "        num_epochs=args.num_epochs,\n",
    "        warmup_steps=args.warmup_steps,\n",
    "        logging_steps=args.logging_steps\n",
    "    )\n",
    "    \n",
    "    if args.output_dir:\n",
    "        trainer.save_model(args.output_dir)\n",
    "    \n",
    "    return losses\n"
   ],
   "id": "97e492c76ca7709d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    parser = argparse.ArgumentParser(description=\"RAG Training Script\")\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--mode\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        choices=[\"retriever\", \"generator\", \"end-to-end\"],\n",
    "        help=\"Режим обучения: retriever, generator, или end-to-end\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\"--batch_size\", type=int, default=4, help=\"Размер батча\")\n",
    "    parser.add_argument(\"--num_epochs\", type=int, default=3, help=\"Количество эпох\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=2e-5, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--warmup_steps\", type=int, default=100, help=\"Warmup steps\")\n",
    "    parser.add_argument(\"--logging_steps\", type=int, default=10, help=\"Logging steps\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, default=None, help=\"Директория для сохранения модели\")\n",
    "    \n",
    "    # Параметры для ретривера\n",
    "    parser.add_argument(\"--num_hard_negatives\", type=int, default=7, help=\"Количество hard negatives\")\n",
    "    parser.add_argument(\"--use_in_batch_negatives\", action=\"store_true\", help=\"Использовать in-batch negatives\")\n",
    "    parser.add_argument(\"--max_length\", type=int, default=256, help=\"Максимальная длина для ретривера\")\n",
    "    \n",
    "    # Параметры для генератора\n",
    "    parser.add_argument(\"--max_input_length\", type=int, default=512, help=\"Максимальная длина входа\")\n",
    "    parser.add_argument(\"--max_output_length\", type=int, default=128, help=\"Максимальная длина выхода\")\n",
    "    \n",
    "    # Параметры для end-to-end обучения\n",
    "    parser.add_argument(\"--retriever_weight\", type=float, default=0.5, help=\"Вес loss ретривера\")\n",
    "    parser.add_argument(\"--generator_weight\", type=float, default=0.5, help=\"Вес loss генератора\")\n",
    "    parser.add_argument(\"--top_k_retrieval\", type=int, default=3, help=\"Top-k для retrieval\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA доступна! Используется GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"CUDA недоступна. Используется CPU.\")\n",
    "    \n",
    "    if args.mode == \"retriever\":\n",
    "        losses = train_retriever(args)\n",
    "    elif args.mode == \"generator\":\n",
    "        losses = train_generator(args)\n",
    "    elif args.mode == \"end-to-end\":\n",
    "        losses = train_rag_end_to_end(args)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ОБУЧЕНИЕ ЗАВЕРШЕНО!\")\n",
    "    print(\"=\"*80)"
   ],
   "id": "aa539e08929e8506"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
