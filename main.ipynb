{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a953a8bf5173ce4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from lib.rag_system import RAGSystem\n",
    "import argparse\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def demo_custom_rag():\n",
    "    \"\"\"\n",
    "    Демонстрация работы кастомной RAG системы (DPR + BART)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"ДЕМОНСТРАЦИЯ КАСТОМНОЙ RAG СИСТЕМЫ (DPR + BART)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    rag = RAGSystem(use_pretrained_rag=False)\n",
    "    documents = [\n",
    "        \"Python is a high-level programming language known for its simplicity and readability.\",\n",
    "        \"Machine learning is a subset of artificial intelligence that enables systems to learn from data.\",\n",
    "        \"The Transformer architecture was introduced in the 'Attention is All You Need' paper in 2017.\",\n",
    "        \"BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained language model.\",\n",
    "        \"GPT (Generative Pre-trained Transformer) is designed for text generation tasks.\",\n",
    "        \"Deep learning uses neural networks with multiple layers to learn hierarchical representations.\",\n",
    "        \"Natural Language Processing (NLP) focuses on the interaction between computers and human language.\",\n",
    "        \"RAG combines retrieval and generation for knowledge-intensive tasks.\",\n",
    "        \"DPR (Dense Passage Retrieval) uses dense embeddings for document retrieval.\",\n",
    "        \"BART is a denoising autoencoder for pretraining sequence-to-sequence models.\",\n",
    "        \"Attention mechanisms allow models to focus on relevant parts of the input.\",\n",
    "        \"Fine-tuning adapts pre-trained models to specific downstream tasks.\",\n",
    "        \"Vector databases store and retrieve high-dimensional embeddings efficiently.\",\n",
    "        \"FAISS is a library for efficient similarity search and clustering of dense vectors.\",\n",
    "        \"The encoder-decoder architecture is fundamental to many NLP models.\"\n",
    "    ]\n",
    "\n",
    "    rag.index_documents(documents)\n",
    "    questions = [\n",
    "        \"What is RAG?\",\n",
    "        \"How does DPR work?\",\n",
    "        \"What is BART used for?\"\n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        result = rag.answer_question_custom(question, top_k=3)\n",
    "        print(f\"\\n[ОТВЕТ] {result['answer']}\")\n",
    "\n"
   ],
   "id": "83c92b9da4a2be3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def demo_pretrained_rag():\n",
    "    \"\"\"\n",
    "    Демонстрация работы предобученной RAG модели\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ДЕМОНСТРАЦИЯ ПРЕДОБУЧЕННОЙ RAG МОДЕЛИ\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    rag = RAGSystem()\n",
    "    questions = [\n",
    "        \"Who was the first president of the United States?\",\n",
    "        \"What is the capital of France?\",\n",
    "        \"When was Python created?\"\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        result = rag.answer_question_pretrained(question)\n",
    "        print(f\"\\n[ВОПРОС] {result['question']}\")\n",
    "        print(f\"[ОТВЕТ] {result['answers'][0]}\")\n",
    "\n"
   ],
   "id": "a822af2329329ce9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# demo_custom_rag() # choose this\n",
    "demo_pretrained_rag() # or choose this\n"
   ],
   "id": "61cb0f96f9c83039"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
